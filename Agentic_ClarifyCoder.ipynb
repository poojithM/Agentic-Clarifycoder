{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIeXvQUDqI8s"
   },
   "source": [
    "**Agentic Clarify Coder**\n",
    "\n",
    "Developed a Agentic ClarifyCoder, a workflow centered on ClarifyCoder a fine-tuned model that explicitly flags uncertainty and asks targeted clarification questions before generating any code. The system adopts a “code-when-certain, ask-when-unsure” posture: it produces code immediately for well-specified prompts, and uses short, focused questions to elicit missing user requirements when ambiguity is detected. The workflow coordinates two agents: Agent 1 reviews the question and, if it is clear, sends it to Agent 2; if it is not, Agent 1 asks clarification questions to the user. Agent 2 generates the code by using user input once ambiguity is resolved. This disciplined clarify-then-code loop reduces brittle guesses, lowers error rates, and measurably improves the reliability and user trust of LLM-based code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LXhPeT6ULTFZ",
    "outputId": "4b8ea954-61a1-4325-b670-0bccbbb13789"
   },
   "outputs": [],
   "source": [
    "!pip -q install transformers peft langgraph langchain-core langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uQRDSStcLfsu"
   },
   "outputs": [],
   "source": [
    "import torch, os\n",
    "from typing import TypedDict, List, Dict, Any\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import PeftModel\n",
    "from langgraph.graph import StateGraph, END\n",
    "from graphviz import Digraph\n",
    "from IPython.display import Image, display\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QZzW6Tusb3x3"
   },
   "source": [
    "**Initializing Clarify Coder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 493,
     "referenced_widgets": [
      "50e15b44ed85418aaa20249b9ca76626",
      "f068cdae41984b87b29ff3fa5e85964b",
      "d653d021bd9947bb87ebd376a09b15f8",
      "49c447526efa4a1185b7edc00920559d",
      "557b0a68170c465c92a1c9cf2a7d8a85",
      "633ce05731c14635b608f7adf9a31fc2",
      "4d7b623f9f4f49a2a2d4a4665f8320a3",
      "c187a51264a74e83912a40403cba1abb",
      "2a173b1f8067462284f5c5e4aff934db",
      "c2e7acd6198846eda15e1dda3e6c6047",
      "e77daa3530ea4622a9366d95e6d8ffe2",
      "a8faad2a78e14ef89f4cc67e6d4b0245",
      "3c623958e7fc49e19e70ba0b15ae6bab",
      "a64b538d29634a6ab9a8e2ae231431f1",
      "891f7e3fcc1e47d2933798ace066286e",
      "6225dfaa3c474e35aca65fdd61836819",
      "8a7058c661494245adb4cfce64a1816f",
      "d35b29de480f465fbdbfc2325a0e6271",
      "246dfdb45a81442d8c4b3e0615a3018b",
      "8f6d17d71c9347838da77b0c6fe63a41",
      "634d1b48d62e48a286822a5a4f749492",
      "6785e0270a5441349532a84b8d4f2ef2",
      "7244c0b6c82f4ec7912c7c18195df7f2",
      "02a53626efbf409bb36e1bd686906204",
      "d21a0498ca544235acb2d5a77e555101",
      "0c8bcbc9c7044f08ad7327f60c8f8e33",
      "e716bb898dab4c96827fbab7ed8a2e54",
      "104738a4402f48d0a535928bb0ce1dfc",
      "9141fb0abc904fe2b66d30b5ba2e5b7a",
      "acce5fed91394d04b06de66d470e4e54",
      "55a56178b8974256a632a4345fcb57d7",
      "99d2d43fa57642d2b564b3381a8f0c53",
      "129b8197062544b7b56c5baff24330de",
      "2f1f04d2580f414f9a07e8a3be841bc6",
      "a271d34fea30461ca3f12c45186a5785",
      "f91061f226ef4745be1a3dff13e40161",
      "e953317a645f4431a155f369e0822589",
      "885586c8650a41769a472ca893497749",
      "3c4aeae2b1ba4764a47c392d00c42388",
      "3bee570b61c54f998e6df9daa7ac0e2f",
      "c3369c87f9ce4618817b6d5669acf93f",
      "0a5293f1f77f45888eba25aa571d7b0f",
      "d9f65e19e9894753b0327dd8620f98cd",
      "36ad30f79eb140bca754789a23c06cff",
      "9af8fa46063040679aa3cfb0f3fb89fc",
      "0d8fb441bfad40918a190c20c5212e46",
      "928d5784111241a59e8aca461689a2f4",
      "b7355567415e4e5f990a16c6606a71f2",
      "58ef2026e07541fe88faf0f2cbf9a1c6",
      "c93556bd22614f25b7ac6e7bf389a9c8",
      "def548e1365c4db99d1b2347edf13444",
      "d4d4ed74f9224e01886230dc9543a66e",
      "243314efe76f4566a7a78b87ef9e1a52",
      "0e8207a949fc4b109255e657a910f3c6",
      "2d9d38b048634e8fb4228ce90720e5b6",
      "82968c4d49264647bde536b1165f8b65",
      "abc0aa68509a4e5baae280fababe7299",
      "ad1bb35a313e4476925cc346361a89b1",
      "8c3f7bfe047249869ef3a691768ad07f",
      "dcdf5342f2704c38a913346e871f6d62",
      "bd582dfb1af6483a8e0bbbef3d492861",
      "1ab9a3e40619426fa90bdaa89211faa5",
      "58ce9c726f4b491d8df7f3a4d1597266",
      "7c10040dcdaa43fbbc1c8ae865ef9b10",
      "b872436c4db34fe080449ee18be23515",
      "2371e1672dac4e0181874856af89586d",
      "06268888e348451388a656f90e6040f7",
      "d059070daceb466dac51fa1a34ddcd4c",
      "7c0586a9c885462ca6bd4d3b638c9fbc",
      "0affe780c26b46668bb399236633770d",
      "d008c05e48fd41fdb425dbfcdfa0504e",
      "d2ecda80afbf45e2bec1a5b8283eaa9f",
      "3dfffde8dea547998ee85906a12fcbd3",
      "43e9018a21e644bb855840eebc5eb0da",
      "4a9892fd70424dca8dc5dd87c28914e4",
      "855533ecc4e74d6d87d9852ef45384ec",
      "362fcaa5141f49ad8096a688865cd71b",
      "f85b34a28b3e4696b065a0cc88a33e22",
      "f4e9c3cd31c349108ab12da1988f65de",
      "308525f7c70740faa77c45e46e2e208e",
      "8adc409e9fb34f3cb639316bae289020",
      "643fb425a7224e028ef336c37ece7d07",
      "787810c8bd8e4b57bef82174e92bba1f",
      "060c3b53d82142168e8fb814c42dd368",
      "d7d037347630420f897f9939600078fa",
      "ff97f45141d6475091deb3972eab6a61",
      "f4cad39bf4bf4a96842472cfea5d29b5",
      "1e0cc211f27642c8a67ad362037a9f28",
      "25efee1ec6324aa28147f1e539dccd86",
      "97be520c561c47b9b95007a3bee65534",
      "a0f82da4452b47a09a824ad1235a735c",
      "44dfde36922541c08db8dd4ce9a8c893",
      "2b4b825022014c309c09e8ae43139d4c",
      "654d890bb2fe4d25896210168ff3793a",
      "8beb1596f7234fde8681780697bf1c6b",
      "697b9818921949019bfe4dc43ebd7f02",
      "38f9a0cb9acf4f5ebad66a984f2c6918",
      "e5b88fc96a464f7a8a95631a0fa8af79",
      "59d906642053492eb95d52231006fcb0",
      "7dd491269c4c4e2684916096a2f77d18",
      "c74088f1173e4d1b833bb6ef734ceeaf",
      "b2845edcd882429ebf79d852e976691d",
      "84c3e4ecd4a3413980781f91bbcd0bf8",
      "4d83f7bd06ad4b16bf8ab8aea6a1589e",
      "4059f77ddc644ee99f82b39137c20c37",
      "0eb934aa3f134b599e2afcad18c019c3",
      "07851cbc4c0a44ff9a454c1b4cfa2e1b",
      "575f781249f64cc4bafaac2c9384dc69",
      "b91d912eb4124dd8810f3713fdf3eb7d",
      "0b8fad627c7a46e1af48c6b9da6229b8",
      "33db7dd700694f1286f0e246460463ca",
      "ef6710ef65a54051a3adf60dccf94602",
      "47630fafa6bd444db9949c2e49c7813a",
      "16a55dbd42384e6b915842af6968f951",
      "90c1677c4ebd4866a59f238fa6bf4e91",
      "bf201f7e34bb43329525e05ae88f5d76",
      "f3ecc6da1d564c3c925c69800126c489",
      "6da683c86c0c426cb610cac2934cf251",
      "cd74d1774751406fb583151515c28f8a",
      "c6e1178af64c452599e8b9d32768b8c8",
      "5f58da8e09e94ff092e368a9f472e75e"
     ]
    },
    "id": "8Ff6_3LUZP_9",
    "outputId": "b694ab9d-b5f7-4dea-b803-f50c2de7d6cc"
   },
   "outputs": [],
   "source": [
    "Base_model  = \"deepseek-ai/deepseek-coder-6.7b-instruct\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(Base_model, use_fast=True, trust_remote_code=True)\n",
    "\n",
    "#Loading the Deepseek-coder model\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    Base_model,\n",
    "    dtype=torch.float16 if torch.cuda.is_available() else torch.float32,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "#Loading Clarify-Coder Adaper\n",
    "model = PeftModel.from_pretrained(base_model, \"jie-jw-wu/clarify-coder\").eval()\n",
    "device = next(model.parameters()).device\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eDmpb3Tlb4pV"
   },
   "source": [
    "**Function to Generate response from language model**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iStydlNhLlEc"
   },
   "outputs": [],
   "source": [
    "def response(messages: list[dict[str, str]],max_new_tokens: int,temperature: float) -> str:\n",
    "\n",
    "    prompt = tokenizer.apply_chat_template(messages,tokenize=False,add_generation_prompt=True)\n",
    "\n",
    "    #Tokenizing the Prompt\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    #Generating Output\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=max_new_tokens,\n",
    "            temperature=temperature,\n",
    "            top_p=0.95,\n",
    "            do_sample=(temperature > 0),\n",
    "            repetition_penalty=1.05,\n",
    "            eos_token_id=tokenizer.eos_token_id,\n",
    "            pad_token_id=(tokenizer.pad_token_id or tokenizer.eos_token_id),\n",
    "        )\n",
    "\n",
    "    #Decoding the generated output to text\n",
    "    full_sequence = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_sequence[len(prompt):].strip() if full_sequence.startswith(prompt) else full_sequence.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UbPbtwL0HhS_"
   },
   "source": [
    "**Two Agentic Flow**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U_pR-ioNJvdw"
   },
   "source": [
    "**TwoState Class manages the shared state in the Agentic workflow,**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KElhWlzLHsk7"
   },
   "outputs": [],
   "source": [
    "#Shared state\n",
    "class TwoState(TypedDict, total=False):\n",
    "    problem: str\n",
    "    answers: str\n",
    "    questions: str\n",
    "    needs_clarification: bool\n",
    "    final_code: str\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wc0P3YGPJ7MG"
   },
   "source": [
    "**Agent1**\n",
    "\n",
    "This agent will understand the user problem and generate clarify question if Problem is unclear if not generate OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZrZulmy9HsxF"
   },
   "outputs": [],
   "source": [
    "def AnalyzerAgent1(state: TwoState) -> TwoState:\n",
    "    \"\"\"Agent 1: Question Analyzer - determines if problem is clear or needs clarification\"\"\"\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a problem analyzer. Determine if the problem is clear enough to code.\\n\\n\"\n",
    "            \"OUTPUT RULES:\\n\"\n",
    "            \"- If the problem is clear and specific, respond EXACTLY: OK\\n\"\n",
    "            \"- If the problem is vague or missing details, ask 1-4 numbered questions\\n\"\n",
    "            \"- Format questions as: '1. Question here\\\\n2. Another question\\\\n'\\n\"\n",
    "            \"- NO explanations, NO code, NO other text\\n\\n\"\n",
    "\n",
    "            \"Examples of CLEAR problems (respond OK):\\n\"\n",
    "            \"- 'Write a function to add two numbers 4 and 5'\\n\"\n",
    "            \"- 'Create a function to reverse a string Amercia'\\n\"\n",
    "            \"- 'Find the maximum number in a list of 5 elements'\\n\\n\"\n",
    "\n",
    "            \"Examples of UNCLEAR problems (ask questions):\\n\"\n",
    "            \"- Return the list increment by number (what number?)\\n\"\n",
    "            \"- 'Sort an array' (which algorithm? ascending/descending?)\\n\"\n",
    "            \"- 'Create a calculator' (what operations? GUI or CLI?)\\n\"\n",
    "            \"- 'Process data' (what kind of processing? what format?)\\n\\n\"\n",
    "            \"Only ask questions if genuinely ambiguous.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Analyze this problem: {state['problem']}\\n\\nIs this clear enough to implement without ambiguity?\"\n",
    "    }\n",
    "\n",
    "    # Generate analysis\n",
    "    raw_output = response([system_msg, user_msg], max_new_tokens=300, temperature=0.0).strip()\n",
    "\n",
    "    # Clean up the output\n",
    "    lines = [line.strip() for line in raw_output.split('\\n') if line.strip()]\n",
    "\n",
    "    # Check if it's OK\n",
    "    if any(line.upper() == \"OK\" for line in lines):\n",
    "        out_final = \"OK\"\n",
    "        needs = False\n",
    "        print(\"Agent 1: Problem is CLEAR - OK\")\n",
    "    else:\n",
    "        # Extract numbered questions\n",
    "        questions = []\n",
    "        for line in lines:\n",
    "            if re.match(r'^[1-4]\\.\\s+', line):\n",
    "                questions.append(line)\n",
    "\n",
    "        if questions and len(questions) <= 4:\n",
    "            out_final = '\\n'.join(questions)\n",
    "            needs = True\n",
    "            print(\"Agent 1: Problem is UNCLEAR - Questions needed\")\n",
    "            print(out_final)\n",
    "        else:\n",
    "            # Default to OK if no clear questions\n",
    "            out_final = \"OK\"\n",
    "            needs = False\n",
    "            print(\"Agent 1: Defaulting to OK\")\n",
    "\n",
    "    # Update state\n",
    "    new = dict(state)\n",
    "    new[\"needs_clarification\"] = needs\n",
    "    new[\"questions\"] = out_final if needs else \"\"\n",
    "    if needs and not state.get(\"answers\"):\n",
    "        new[\"status\"] = \"awaiting_answers\"\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h98w6u_oKSUi"
   },
   "source": [
    "The route function directs the workflow after Agent 1 sending it to await for user requirements or to refine for final code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQsh_0utHs0O"
   },
   "outputs": [],
   "source": [
    "# Simple 2-agent workflow routing\n",
    "def route_after_agent1(state: TwoState) -> str:\n",
    "    if state.get(\"needs_clarification\") and not state.get(\"answers\"):\n",
    "        return \"await\"\n",
    "    return \"generate_code\"\n",
    "\n",
    "def await_for_user_input(state: TwoState) -> TwoState:\n",
    "    new = dict(state)\n",
    "    new[\"status\"] = \"awaiting_answers\"\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vNEkF5msSPLe"
   },
   "source": [
    "**Agent 2**\n",
    "\n",
    "This agent will complete the final code by understanding the problem statement and user requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MgysUVPWHs3W"
   },
   "outputs": [],
   "source": [
    "#Agent 2\n",
    "def CoderAgent2(state: TwoState) -> TwoState:\n",
    "    \"\"\"Agent 2: Code Generator - generates executable code based on problem and requirements\"\"\"\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a Python code generator. Create complete, executable Python code.\\n\\n\"\n",
    "            \"RULES:\\n\"\n",
    "            \"- Generate ONE complete, working Python program\\n\"\n",
    "            \"- If user provided requirements, implement them exactly\\n\"\n",
    "            \"- Write clean, production-ready code\\n\"\n",
    "            \"- Start directly with the code\\n\\n\"\n",
    "            \"Create a complete solution that works immediately.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    # Create prompt based on whether user provided requirements\n",
    "    if state.get('questions') and state.get('answers'):\n",
    "        print(\"Agent 2: Generating code with USER REQUIREMENTS\")\n",
    "        prompt = (\n",
    "            f\"Create Python code that implements the user's specific requirements.\\n\\n\"\n",
    "            f\"PROBLEM: {state['problem']}\\n\\n\"\n",
    "            f\"QUESTIONS ASKED: {state['questions']}\\n\\n\"\n",
    "            f\"USER REQUIREMENTS: {state['answers']}\\n\\n\"\n",
    "            f\"TASK: Create complete Python code that follows the user's specifications exactly. \"\n",
    "            f\"Implement each requirement they provided.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\"Agent 2: Generating code for CLEAR PROBLEM\")\n",
    "        prompt = (\n",
    "            f\"Create Python code for this clear problem.\\n\\n\"\n",
    "            f\"PROBLEM: {state['problem']}\\n\\n\"\n",
    "            f\"TASK: Create complete, executable Python code that solves this problem. \"\n",
    "            f\"Include example usage.\"\n",
    "        )\n",
    "\n",
    "    # Generate code\n",
    "    raw_output = response([system_msg, {\"role\": \"user\", \"content\": prompt}], max_new_tokens=1500, temperature=0.0).strip()\n",
    "\n",
    "    # Clean up the output using your existing clean function\n",
    "    code_pattern = re.compile(r\"(?:```python\\s*\\n(.*?)\\n\\s*```|### Response:\\s*\\n(.*))\", re.DOTALL)\n",
    "    match = code_pattern.search(raw_output)\n",
    "    if match:\n",
    "        final_code = (match.group(1) or match.group(2)).strip()\n",
    "    else:\n",
    "        final_code = raw_output.strip()\n",
    "\n",
    "\n",
    "\n",
    "    # Update state\n",
    "    new = dict(state)\n",
    "    new[\"final_code\"] = final_code\n",
    "    new[\"status\"] = \"finalized\"\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_-sabsAsKdaA"
   },
   "source": [
    "**StateGraph**\n",
    "\n",
    "Building StateGraph for Two Agentic Workflow, Connecting Agent1, Agent2 with conditional routing to handle clarifications and finalize Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h-yAlqCiHs51"
   },
   "outputs": [],
   "source": [
    "#Build the graph\n",
    "builder = StateGraph(TwoState)\n",
    "builder.add_node(\"AnalyzerAgent1\", AnalyzerAgent1)  # Question analyzer\n",
    "builder.add_node(\"CoderAgent2\", CoderAgent2)  # Code generator\n",
    "builder.add_node(\"await_for_user_input\", await_for_user_input)\n",
    "builder.set_entry_point(\"AnalyzerAgent1\")\n",
    "builder.add_conditional_edges(\"AnalyzerAgent1\", route_after_agent1, {\"await\": \"await_for_user_input\", \"generate_code\": \"CoderAgent2\"})\n",
    "builder.add_edge(\"await_for_user_input\", END)\n",
    "builder.add_edge(\"CoderAgent2\", END)\n",
    "clarify_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZ1PDkMMKl1e"
   },
   "source": [
    "**Vizualize State Grpah**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "4cDR8-V1Hs8c",
    "outputId": "bc267ecb-eead-42df-8c9c-3fa8405ea68f"
   },
   "outputs": [],
   "source": [
    "\n",
    "from graphviz import Digraph\n",
    "\n",
    "# Create a new directed graph\n",
    "dot = Digraph(comment='ClarifyCoder StateGraph', format='png')\n",
    "\n",
    "# Define nodes\n",
    "dot.node('AnalyzerAgent1', 'AnalyzerAgent1\\n(Problem Analyzer)', shape='box', style='filled', fillcolor='lightblue')\n",
    "dot.node('CoderAgent2', 'CoderAgent2\\n(Code Generator)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "dot.node('await_for_user_input', 'Await User Input', shape='box', style='filled', fillcolor='lightyellow')\n",
    "dot.node('END', 'END', shape='circle', style='filled', fillcolor='red')\n",
    "\n",
    "# Define edges\n",
    "dot.edge('AnalyzerAgent1', 'CoderAgent2', label='generate_code', style='bold')\n",
    "dot.edge('AnalyzerAgent1', 'await_for_user_input', label='await (unclear)', style='dashed')\n",
    "dot.edge('await_for_user_input', 'CoderAgent2', label='proceed after input', style='dotted')\n",
    "dot.edge('CoderAgent2', 'END')\n",
    "\n",
    "# Set entry point (visual cue)\n",
    "dot.node('START', 'START', shape='circle', style='filled', fillcolor='grey')\n",
    "dot.edge('START', 'AnalyzerAgent1', label='Entry', style='bold')\n",
    "\n",
    "# Render the graph to a file\n",
    "dot.render('TwoAgent', view=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 607
    },
    "id": "LUKoGekMHs_P",
    "outputId": "6ed8ebb7-356b-49ea-a1b7-712afc6831f4"
   },
   "outputs": [],
   "source": [
    "display(Image(filename='TwoAgent.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K1VzePWsLKSl"
   },
   "source": [
    "**Two Agentic Workflow**\n",
    "\n",
    "This function manually executes the Two Agentic workflow, reviewing the user question with Agent1, collecting user clarification if needed, and producing final code with Agent2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HAGCpbwKHtFY"
   },
   "outputs": [],
   "source": [
    "def agentic_clarify_coder(problem: str):\n",
    "    \"\"\"Run the 2-agent ClarifyCoder workflow\"\"\"\n",
    "\n",
    "    print(f\"Processing problem: {problem}\\n\")\n",
    "\n",
    "    #Agent 1 analyzes the problem\n",
    "    print(\"Agent 1: Analyzing problem clarity...\")\n",
    "    state = {\"problem\": problem}\n",
    "    state = AnalyzerAgent1(state)\n",
    "    print(\"=\"*50)\n",
    "\n",
    "    # Handle clarification if needed\n",
    "    if state.get(\"needs_clarification\"):\n",
    "        print(\"Clarifying questions:\")\n",
    "        print(state[\"questions\"])\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # Get user input\n",
    "        print(\"Please provide answers to the questions above:\")\n",
    "        answers = input(\"Your answers: \")\n",
    "\n",
    "        # Add answers to state\n",
    "        state[\"answers\"] = answers\n",
    "        print(f\"Received answers: {answers[:100]}...\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "    #Agent 2 generates the code\n",
    "    print(\"🔧 Agent 2: Generating code...\")\n",
    "    state = CoderAgent2(state)\n",
    "\n",
    "    # Output final code\n",
    "    if state.get(\"final_code\"):\n",
    "        print(\"\\nFinal Code:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(state[\"final_code\"])\n",
    "        return state[\"final_code\"]\n",
    "    else:\n",
    "        print(\"Error: Could not generate final code\")\n",
    "        return None\n",
    "        if state.get(\"final_code\") == \"\":\n",
    "            print(\"Final code is empty string\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dB3YRD2nQtZm",
    "outputId": "f6bde404-4b86-4180-89ff-3343c133c9fd"
   },
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    result1 = agentic_clarify_coder(\"Write a python code to sort a list\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ht9RkvB_Ldql"
   },
   "source": [
    "**Okanagan Agentic Flow**\n",
    "\n",
    "This approach uses the Okanagan workflow. The Agent 1 will create the draft code based on the initial problem statement, providing a preliminary solution without making assumptions. Agent 2 will then evaluate the draft code to determine if it fully addresses the problem. If the draft does not solve the problem or contains ambiguities, Agent 2 generates concise, targeted clarification questions to elicit missing user requirements. Once the user provides the necessary clarifications, Agent 2 sends these requirements to Agent 3. If the draft is deemed sufficient, Agent 2 directly forwards it to Agent 3 without additional questions. Agent 3 then generates the final, production-ready code, incorporating the draft and any clarified requirements, ensuring a robust and reliable output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ooBYvPIgb6vG"
   },
   "source": [
    "**OkState Class manages the shared state in the Okanagan workflow,**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TEE3XBlYgvB8"
   },
   "outputs": [],
   "source": [
    "#Shared state\n",
    "class OkState(TypedDict, total=False):\n",
    "    problem: str\n",
    "    answers: str\n",
    "    draft_code: str\n",
    "    questions: str\n",
    "    needs_clarification: bool\n",
    "    final_code: str\n",
    "    status: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o4qsKRoLg3oA"
   },
   "source": [
    "**Agent1**\n",
    "\n",
    "This agent will understand the user problem and generate the draft code for it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fHz0bqXJg0H2"
   },
   "outputs": [],
   "source": [
    "\n",
    "def Agent1(state: OkState) -> OkState:\n",
    "\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a Python developer. Create a step by step draft code that solves the problem.\\n\\n\"\n",
    "            \"RULES:\\n\"\n",
    "            \"- Write a Code that addresses the problem.\\n\"\n",
    "            \"- Write a detailed algorithm that solves the problem without using inbuilt functions\"\n",
    "            \"- Use generic parameter names (like 'arr', 'data', 'items') instead of input values\\n\"\n",
    "            \"- DO NOT include specific values or test data given in problem\\n\"\n",
    "            \"- DO NOT make assumptions about specific requirements\\n\"\n",
    "            \"- Keep the implementation basic and general\\n\"\n",
    "            \"- No example calls or test data\\n\\n\"\n",
    "            \"NOTE Anyways generate the draft code\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    user_msg = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Create a Python code for: {state['problem']}\"\n",
    "    }\n",
    "\n",
    "\n",
    "    #Generating Draft code\n",
    "    raw = response([system_msg, user_msg], max_new_tokens=1200, temperature=0.1).strip()\n",
    "\n",
    "    #Extract the code in between ```python ```\n",
    "    # Extract code between ```python ... ``` or after ### Response:\n",
    "    code_pattern = re.compile(r\"(?:```python\\s*\\n(.*?)\\n\\s*```|### Response:\\s*\\n(.*))\", re.DOTALL)\n",
    "    match = code_pattern.search(raw)\n",
    "    if match:\n",
    "        final_code = (match.group(1) or match.group(2)).strip()\n",
    "    else:\n",
    "        final_code = final_code.strip()\n",
    "\n",
    "    #print(final_code)\n",
    "    #Update state with the draft code\n",
    "    new = dict(state)\n",
    "    new[\"draft_code\"] = final_code\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2NVVz_UMhFZB"
   },
   "source": [
    "**Agent 2**\n",
    "\n",
    "This agent acts as a code reviewer to determine if Agent 1 fully solved the problem or if additional requirements are needed for a better outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "g6Qo6-NPhF0J"
   },
   "outputs": [],
   "source": [
    "#Agent 2\n",
    "def Agent2(state: OkState) -> OkState:\n",
    "\n",
    "    #Define system message for strict code review, enforcing \"OK\" or 1-4 Questions\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a balanced code reviewer. Analyze if the problem is clear enough to implement.\\n\\n\"\n",
    "            \"OUTPUT RULES:\\n\"\n",
    "            \"- If the problem is clear and can be implemented without ambiguity, respond EXACTLY: OK\\n\"\n",
    "            \"- If the problem is vague or missing critical details, ask 1-4 numbered questions\\n\"\n",
    "            \"- Format questions as: '1. Question here\\\\n2. Another question\\\\n'\\n\"\n",
    "            \"- NO explanations, NO code, NO other text\\n\\n\"\n",
    "            \"Examples of CLEAR problems (respond OK):\\n\"\n",
    "            \"- 'Write a function to add two numbers values are 1 and 2'\\n\"\n",
    "            \"- 'Create a function to reverse a string America'\\n\"\n",
    "            \"- 'Write code to find the maximum number in a list'\\n\\n\"\n",
    "            \"Examples of UNCLEAR problems (ask questions):\\n\"\n",
    "            \"- 'Sort an array' (which algorithm? ascending/descending?)\\n\"\n",
    "            \"- 'Process user data' (what kind of processing? what format?)\\n\"\n",
    "            \"- 'Create a calculator' (what operations? GUI or CLI?)\\n\\n\"\n",
    "            \"Only ask questions if there are genuinely multiple ways to interpret the problem.\"\n",
    "        )\n",
    "    }\n",
    "\n",
    "    prompt = (\n",
    "        f\"Review this problem for clarity:\\n\\n\"\n",
    "        f\"PROBLEM: {state['problem']}\\n\\n\"\n",
    "        f\"DRAFT CODE:\\n{state['draft_code']}\\n\\n\"\n",
    "        f\"Is this problem clear enough to implement without ambiguity? \"\n",
    "        f\"If yes, respond 'OK'. If no, ask specific clarifying questions.\"\n",
    "    )\n",
    "\n",
    "\n",
    "    # Generate review output using the Clarify Coder\n",
    "    raw_output = response([system_msg, {\"role\": \"user\", \"content\": prompt}], max_new_tokens=2000, temperature=0.2).strip()\n",
    "\n",
    "\n",
    "    #Extracting the Response\n",
    "    code = re.compile(r\"(?:###\\s*Response:\\s*(.*))|(?:Clarifying questions:\\s*\\n(.*))\",\n",
    "                  re.DOTALL | re.IGNORECASE)\n",
    "    searching = code.search(raw_output)\n",
    "    out = (searching.group(1) or searching.group(2)).strip() if searching else raw_output.strip()\n",
    "\n",
    "    # Filtering the questions\n",
    "    lines = [ln.strip() for ln in out.splitlines() if ln.strip()]\n",
    "    question = [ln for ln in lines if re.match(r\"^[1-4]\\.\\s+\\S\", ln)]\n",
    "    exact_ok = any(ln == \"OK\" for ln in lines)\n",
    "\n",
    "    #If Valid Questions, Set clarification path else OK\n",
    "    if 1 <= len(question) <= 4:\n",
    "        out_final = \"\\n\".join(question)\n",
    "        needs = True\n",
    "    else:\n",
    "        out_final = \"OK\"\n",
    "        needs = False\n",
    "\n",
    "\n",
    "\n",
    "    #updating the states\n",
    "    new = dict(state)\n",
    "    new[\"needs_clarification\"] = needs\n",
    "    new[\"questions\"] = out_final if needs else \"\"\n",
    "    if needs and not state.get(\"answers\"):\n",
    "        new[\"status\"] = \"awaiting_answers\"\n",
    "\n",
    "\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i3xjNUL4hSvJ"
   },
   "source": [
    "The route function directs the workflow after Agent 2 sending it to await for user requirements or to refine for final code generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fnD5NQbyhS_i"
   },
   "outputs": [],
   "source": [
    "#Direct Workflow based on needs\n",
    "def route(state: OkState) -> str:\n",
    "    if state.get(\"needs_clarification\") and not state.get(\"answers\"):\n",
    "        return \"await\"\n",
    "    return \"refine\"\n",
    "\n",
    "#Pass state through while waiting for user input\n",
    "def await_for_user_input(state: OkState) -> OkState:\n",
    "    \"\"\"This node just passes through the state when waiting for user input\"\"\"\n",
    "    new = dict(state)\n",
    "    new[\"status\"] = \"awaiting_answers\"\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s1KWLHt7hXGA"
   },
   "source": [
    "**Agent 3**\n",
    "\n",
    "This agent will complete the final code by understanding the problem statement, draft code, and user requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XcsO1A7XhXWG"
   },
   "outputs": [],
   "source": [
    "def Agent3(state: OkState) -> OkState:\n",
    "    # System message: Instruct model to output only executable Python code\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"\"\"You are Agent 3: Final Code Generator. Your job is to create executable Python code.\\n\\n\"\n",
    "            \"CRITICAL RULES:\\n\"\n",
    "            \"- If USER ANSWERS are provided, you MUST implement them exactly\\n\"\n",
    "            \"- Do NOT just copy the draft code - MODIFY it based on user requirements\\n\"\n",
    "            \"- Each user answer specifies a requirement you must implement\\n\"\n",
    "            \"- Generate complete, working Python code\\n\"\n",
    "            \"- Include example usage\\n\"\n",
    "            \"- NO explanations or markdown\\n\"\n",
    "            \"- Start directly with code\\n\\n\"\n",
    "            \"Your output must reflect ALL user requirements, not just the draft.\"\"\"\n",
    "        ),\n",
    "    }\n",
    "\n",
    "    # Create prompt based on whether clarifications exist\n",
    "    if state.get('questions') and state.get('answers'):\n",
    "      prompt = (\n",
    "            f\"You must create code that implements the user's specific requirements.\\n\\n\"\n",
    "            f\"ORIGINAL PROBLEM: {state['problem']}\\n\\n\"\n",
    "            f\"QUESTIONS ASKED:\\n{state['questions']}\\n\\n\"\n",
    "            f\"USER'S SPECIFIC REQUIREMENTS:\\n{state['answers']}\\n\\n\"\n",
    "            f\"CRITICAL TASK:\\n\"\n",
    "            f\"The user has provided specific answers about how they want the code to work. \"\n",
    "            f\"You MUST implement their requirements exactly. Do NOT just return the draft code. \"\n",
    "            f\"Analyze each user answer and implement those specific requirements.\\n\\n\"\n",
    "            f\"For example:\\n\"\n",
    "            f\"- If they specified 'bubble sort', implement bubble sort algorithm\\n\"\n",
    "            f\"- If they specified 'ascending order', sort in ascending order\\n\"\n",
    "            f\"- If they specified input format, use that exact format\\n\\n\"\n",
    "            f\"Create complete Python code that follows their specifications:\"\n",
    "        )\n",
    "    else:\n",
    "      prompt = (\n",
    "             f\"TASK: Convert draft algorithm into executable Python code.\\n\\n\"\n",
    "            f\"PROBLEM: {state['problem']}\\n\\n\"\n",
    "            f\"DRAFT ALGORITHM:\\n{state.get('draft_code', '')}\\n\\n\"\n",
    "            f\"INSTRUCTIONS:\\n\"\n",
    "            f\"1. Make it fully executable and complete\\n\"\n",
    "            f\"2. Add proper implementation details\\n\"\n",
    "            f\"3. Add example usage with sample data\\n\\n\"\n",
    "            f\"Generate the complete executable Python code:\"\n",
    "        )\n",
    "\n",
    "    # Generate final code using the clarify-coder model\n",
    "    final_code = response([system_msg, {\"role\": \"user\", \"content\": prompt}], max_new_tokens=1500, temperature=0.0).strip()\n",
    "\n",
    "    def compile_lang_pattern(lang: str) -> re.Pattern:\n",
    "      lang = re.escape(lang)\n",
    "      return re.compile(\n",
    "        rf\"(?:```{lang}\\s*\\n(.*?)\\n\\s*```)|(?:^###\\s*Response:\\s*\\n(.*))\",\n",
    "        re.DOTALL | re.IGNORECASE | re.MULTILINE\n",
    "    )\n",
    "\n",
    "    code_pattern = compile_lang_pattern(\"python\")\n",
    "    m = code_pattern.search(final_code)\n",
    "    final_code = (m.group(1) or m.group(2)).strip() if m else final_code.strip()\n",
    "\n",
    "\n",
    "    # Update state with final code and status\n",
    "    new = dict(state)\n",
    "    new[\"final_code\"] = final_code\n",
    "    new[\"status\"] = \"finalized\"\n",
    "\n",
    "\n",
    "    return new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8mXFMho9hacI"
   },
   "source": [
    "**StateGraph**\n",
    "\n",
    "Building StateGraph for Okanagan Workflow, Connecting Agent1, Agent2, Agent3 with conditional routing to handle clarifications and finalize Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3a3gBb8Uhaqi"
   },
   "outputs": [],
   "source": [
    "#Build the graph\n",
    "builder = StateGraph(OkState)\n",
    "builder.add_node(\"Agent1\", Agent1)\n",
    "builder.add_node(\"Agent2\", Agent2)\n",
    "builder.add_node(\"Agent3\", Agent3)\n",
    "builder.add_node(\"await_for_user_input\", await_for_user_input)\n",
    "builder.set_entry_point(\"Agent1\")\n",
    "builder.add_edge(\"Agent1\", \"Agent2\")\n",
    "builder.add_conditional_edges(\"Agent2\", route, {\"await\": \"await_for_user_input\", \"refine\": \"Agent3\"})\n",
    "builder.add_edge(\"await_for_user_input\", END)\n",
    "builder.add_edge(\"Agent3\", END)\n",
    "okanagan_graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hbvEc59omblR",
    "outputId": "1020331c-40bd-4f72-d7e5-ce2c782009e8"
   },
   "outputs": [],
   "source": [
    "# Create a new directed graph\n",
    "dot = Digraph(comment='Okanagan StateGraph', format='png')\n",
    "\n",
    "# Define nodes\n",
    "dot.node('Agent1', 'Agent1\\n(Generate Draft Code)', shape='box', style='filled', fillcolor='lightblue')\n",
    "dot.node('Agent2', 'Agent2\\n(Clarification)', shape='box', style='filled', fillcolor='lightgreen')\n",
    "dot.node('Agent3', 'Agent3\\n(Executer)', shape='box', style='filled', fillcolor='lightyellow')\n",
    "dot.node('await_for_user_input', 'Await User Input', shape='box', style='filled', fillcolor='lightgrey')\n",
    "dot.node('END', 'END', shape='circle', style='filled', fillcolor='red')\n",
    "\n",
    "# Define edges\n",
    "dot.edge('Agent1', 'Agent2')\n",
    "dot.edge('Agent2', 'Agent3', label='refine (clear)', style='bold')\n",
    "dot.edge('Agent2', 'await_for_user_input', label='await (unclear)', style='dashed')\n",
    "dot.edge('await_for_user_input', 'Agent3', label='proceed after input', style='dotted')\n",
    "dot.edge('Agent3', 'END')\n",
    "\n",
    "# Set entry point\n",
    "dot.node('START', 'START', shape='circle', style='filled', fillcolor='grey')\n",
    "dot.edge('START', 'Agent1', label='Entry', style='bold')\n",
    "\n",
    "# Render the graph to a file\n",
    "dot.render('Three_agent_graph.png', view=True)\n",
    "print(\"Graph visualization saved as Three_agent_graph.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "cYAKS-gHmeCq",
    "outputId": "705d4c40-8ba8-4398-d057-f5936371e9b0"
   },
   "outputs": [],
   "source": [
    "display(Image(filename='Three_agent_graph.png.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZ7QajR1hfmE"
   },
   "source": [
    "**Okanagan Workflow**\n",
    "\n",
    "This function manually executes the Okanagan workflow, generating a draft with Agent1, reviewing it with Agent2, collecting user clarification if needed, and producing final code with Agent3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7CDHKk-hf33"
   },
   "outputs": [],
   "source": [
    "#Run Okanagan workflow interactively\n",
    "\n",
    "def run_okanagan_interactive(problem: str):\n",
    "    \"\"\"Run the Okanagan technique with interactive clarification\"\"\"\n",
    "\n",
    "    print(f\"Processing problem: {problem}\\n\")\n",
    "\n",
    "    #Generate initial draft\n",
    "    print(\"Generating initial draft\")\n",
    "    state = {\"problem\": problem}\n",
    "    state = Agent1(state)\n",
    "    print(f\"Draft generated: {len(state['draft_code'])} characters\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "    # Reviewing the draft\n",
    "    print(\"Reviewing draft\")\n",
    "    state = Agent2(state)\n",
    "\n",
    "    # Show if clarification is needed\n",
    "    if state.get(\"needs_clarification\"):\n",
    "        print(\"Reviewer says: NEEDS CLARIFICATION\")\n",
    "    else:\n",
    "        print(\"Reviewer says: OK - No clarification needed\")\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "    # Collect user answer if clarification is needed\n",
    "    if state.get(\"needs_clarification\"):\n",
    "        print(\"Clarifying questions:\")\n",
    "        print(state[\"questions\"])\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "\n",
    "        # Getting user input\n",
    "        print(\"Please provide answers to the questions above:\")\n",
    "        answers = input(\"Your answers: \")\n",
    "\n",
    "        # Adding answers to state\n",
    "        state[\"answers\"] = answers\n",
    "        print(f\"Received answers: {answers[:100]}...\")\n",
    "\n",
    "\n",
    "\n",
    "    # Generate final code\n",
    "    print(\" Generating final code...\")\n",
    "\n",
    "\n",
    "    state = Agent3(state)\n",
    "\n",
    "    #Output final Code\n",
    "    if state.get(\"final_code\"):\n",
    "        print(\"\\nFinal Code:\")\n",
    "        print(\"-\" * 40)\n",
    "        print(state[\"final_code\"])\n",
    "        return state[\"final_code\"]\n",
    "    else:\n",
    "        print(\"Error: Could not generate final code\")\n",
    "        print(\"Debug - Final state keys:\", list(state.keys()))\n",
    "        if state.get(\"final_code\") == \"\":\n",
    "            print(\"Final code is empty string\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "poHiXgSOL9DC",
    "outputId": "79d0491c-d092-4e15-acdb-3051beb20141"
   },
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    result1 = run_okanagan_interactive(\"Write a python code to sort the array\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ueH5zIEvU5a2"
   },
   "source": [
    "**Result**\n",
    "\n",
    "The Okanagan flow remains a strong baseline: its three-agent structure encourages careful requirement checking and often yields high-quality code when specs are clear. However, because there are more agents, the response time increases and with LLMs inherent fuzziness, small variations from any single agent can propagate, occasionally lowering overall consistency\n",
    "\n",
    "Building from Okanagan, I developed a two-agent clarifyCoder flow. if the problem is not clear it asks brief clarifications up front and then generating code directly, it uses fewer hops, achieves lower latency, and shows more consistent outputs across runs. In practice, this streamlined graph reduces failure modes, minimizes stochastic drift between stages, and keeps the solution tightly aligned with the clarified requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LjzgIHsgVsv0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
